{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1f84fd0-3adb-4f95-986f-10813f6e3e19",
   "metadata": {},
   "source": [
    "# Introducción a Teoría de Juegos \n",
    "\n",
    "Facultad de Economía, UNAM. Versión: noviembre 10, 2022.\n",
    "\n",
    "34 alumnas y alumnos. \n",
    "\n",
    "Pedro José Martínez Alanis, pj.martinez.alanis@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb45047-2286-43fd-82ac-ffcba8ba0ad7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Temas a cubrir en dos clases de Juegos con Información Perfecta\n",
    "\n",
    "#### Equilibrio de Nash: Teoría\n",
    "* Juegos estrátegicos\n",
    "* Equilibrio de Nash \n",
    "    * Dilema del prisionero\n",
    "* Funciones de mejor respuesta\n",
    "* Estrategias dominantes\n",
    "\n",
    "#### Aplicaciones del Equilibrio de Nash\n",
    "* Modelo de oligopolio de Cournot\n",
    "* Modelo de oligopolio de Bertrand\n",
    "* Subastas\n",
    "\n",
    "## Referencias\n",
    "\n",
    "* Capítulos 2 y 3, An Introduction to Game Theory by Martin J. Osborne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe47e8d-e809-4b0c-96f4-a9f0ce662613",
   "metadata": {},
   "source": [
    "# Equilibrio de Nash: Teoría"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77107279-5022-41eb-be47-07486d4b328d",
   "metadata": {},
   "source": [
    "#### Definición (Juego estratégico con preferencias ordinales)\n",
    "Un juego estratégico (con preferencias ordinales) se define como: \n",
    "\n",
    "* un conjunto de **jugadores**\n",
    "* para cada jugador, un conjunto de **acciones**\n",
    "* para cada jugador, **preferencias** sobre el conjunto de perfiles de acciones (*action profiles*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79abcf76-7984-41cb-b3fd-ad80ede9dc81",
   "metadata": {},
   "source": [
    "---\n",
    "Nota: \n",
    "Es común especificar las preferencias de los jugadores a través de la función de pagos en una matriz. Estos pagos solo tienen un significado ordinal.\n",
    "El tiempo se excluye del modelo. La idea es que cada agente escoge sus acciones \"simultaneamente\" en el sentido de que ningún agente o jugador esta informado, al momento de le elegir su acción, de las acciones elegidas por los demás agentes del juego. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d02f4b-36f7-424f-91fd-0280a2ac175c",
   "metadata": {},
   "source": [
    "## El dilema del prisionero\n",
    "\n",
    "Dos sospechosos de un crimen son interrogados en celdas separadas. \n",
    "Hay evidencia suficiente de que alguno de ellos ha cometido un delito menor, pero no tienen pruebas para declarar culpable a alguno de ellos de un crimen mayor a menos de que uno de ellos sea un informante que sirva de testigo frente al otro. \n",
    "Si los dos se quedan callados, entonces cada uno recibirá una condena por delito menor y pasarán un año en prisión. \n",
    "Si solo uno de los dos decide hablar como testigo contra el otro (soplón), este último recibirá 4 años de prisión. \n",
    "Si los dos deciden hablar y actuan como testigo contra el otro, cada uno recibirá 3 años de prisión. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4450b90-a55c-4600-a7ce-8301ad031261",
   "metadata": {},
   "source": [
    "Por tanto, el dilema del prisionero es un juego de estrategias: \n",
    "* Jugadores: los dos sospechosos\n",
    "* Acciones: Cada jugador tiene un conjunto de acciones $\\{Callarse, Soplón \\}$\n",
    "* Preferencias del jugador 1: (Soplón, Callarse), (Callarse, Callerse), (Soplón, Soplón), (Callarse, Soplón). Preferencias del jugador 2: (Callarse, Soplón), (Callarse, Callerse), (Soplón, Soplón), (Soplón, Callarse).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b91983a-a341-461c-994a-02c7f0ca1dc0",
   "metadata": {},
   "source": [
    "#### Representación del juego con una matriz de pagos. \n",
    "Para ello se selecciona una función de pagos que represente las preferencias de los sospechosos. \n",
    "\n",
    "Para el sospechoso 1, se requiere una función tal que: \n",
    "$$\n",
    "u_1(Soplón, Callarse) > u_1(Callarse, Callerse) > u_1(Soplón, Soplón) > u_1(Callarse, Soplón).\n",
    "$$\n",
    "\n",
    "Por ejemplo, se podría especificar la función de pagos $u_1$ tal que: \n",
    "$$\n",
    "u_1(Soplón, Callarse)=3, \\\\ u_1(Callarse, Callerse)=2, \\\\ u_1(Soplón, Soplón)=1, \\\\ u_1(Callarse, Soplón)=0.\n",
    "$$\n",
    "\n",
    "Para el jugador 2, en forma similar se define $u_2$ tal que: \n",
    "\n",
    "$$\n",
    "u_2(Callarse, Soplón)=3, \\\\ u_2(Callarse, Callerse)=2, \\\\ u_2(Soplón, Soplón)=1, \\\\ u_2( Soplón, Callarse)=0.\n",
    "$$\n",
    "\n",
    "Renglones: Sospechoso 1, Columnas: sospechoso 2\n",
    "\n",
    "\n",
    "|   | Callarse  | Soplón  |\n",
    "|---|:---:|:---:|\n",
    "| Callarse  | 2,2  | 0,3  |\n",
    "| Soplón  | 3,0  | 1,1  |\n",
    "\n",
    "El dilema del prisionero es una situación en la cual existen ganancias si cooperan los jugadores (ambos callarse o ambos soplón), pero cada jugador tiene incentivos a desviarse. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08405802-f1ed-44fb-8f09-b6a50a1067cf",
   "metadata": {},
   "source": [
    "## Equilibrio de Nash\n",
    "\n",
    "La solución propuesta por Nash involucra dos componentes. \n",
    "Primero, cada jugador escoge una acción según el modelo de elección racional, dadas sus creencias acerca de las acciones de los otros jugadores. \n",
    "Segundo, las creencias de cada jugador acerca de las acciones de los otros jugadores son correctas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c27cc87-af16-4663-a483-0e0dd531aeb2",
   "metadata": {},
   "source": [
    "Un equilibrio de Nash es un perfil de acciones $a^*$ con la propiedad de que ningún jugador $i$ puede mejorar mediante una acción diferente de $a_i^*$, dado que cada jugador $j$ se mantiene con $a_j^*$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1a4659-f5ff-4130-80e0-5955cad1cd84",
   "metadata": {},
   "source": [
    "---\n",
    "Nota: \n",
    "El equilibrio de Nash corresponde a un estado estacionario. \n",
    "Si, cada vez que el juego se presenta, el perfil de acciones es el mismo equilibrio de Nash $a^*$, entonces ningún jugador escoge alguna acción diferente de su correspondiente acción en $a^*$. \n",
    "Por tanto no hay incentivo alguno a desviarse del equilibrio de Nash. \n",
    "\n",
    "En el equilibrio de Nash las creencias de los jugadores acerca de las acciones de los otros jugadores son correctas. Esto implica que las creencias de dos jugadores respecto a las acciones de un tercer jugador, son las mismas. Y por tanto se coordinan las expectativas de los jugadores. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a6d2bd-9ede-4770-bd71-daa7286a6213",
   "metadata": {},
   "source": [
    "#### Definition (Equilibrio de Nash de un juego de estrategias con preferencias ordinales)\n",
    "El perfil de acciones $a^*$ en un juego de estrategias con preferencias ordinales es un **equilibrio de Nash** si, para cada jugador $i$ y para cada acción $a_i$ del jugador $i$, el perfil de acciones $a^*$ es al menos tan bueno según las preferencias del jugador $i$ respecto al perfil de acciones $(a_i, a_{-i}^*$ en donde el jugar $i$ escoge $a_i$ para cada otra acción $a_j^*$ del jugador $j$. \n",
    "\n",
    "En forma equivalente, para cada jugador $i$, \n",
    "\n",
    "$$\n",
    "u_i(a^*) \\geq u_i(a_i, a_{-i}^*) \\text{ para cada acción } a_i \\text{ del jugador } i, \\tag{21.1}\n",
    "$$\n",
    "tal que $u_i$ is una función de pagos que representa las preferencias del jugador $i$. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dfc6fb-fde5-49d9-8ef1-fd721d7f1a75",
   "metadata": {},
   "source": [
    "---\n",
    "Nota: \n",
    "Esta definición no implica que necesariamente deba de existir un equilibrio de Nash. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb7b73d-ca33-4d57-913b-653e3e671aca",
   "metadata": {},
   "source": [
    "### Dilema del prisionero y el equilibrio de Nash\n",
    "\n",
    "De los cuatro posibles pares de acciones del dilema del prisionero, el perfil de acciones (soplón, soplón) es el único equilibrio de Nash. \n",
    "\n",
    "Renglones: Sospechoso 1, Columnas: sospechoso 2\n",
    "\n",
    "\n",
    "|   | callarse  | soplón  |\n",
    "|---|:---:|:---:|\n",
    "| callarse  | 2,2  | 0,3  |\n",
    "| soplón  | 3,0  | 1,1  |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcc596c-ea50-4031-860c-d083d4a395be",
   "metadata": {},
   "source": [
    "### Equilibrio de Nash estricto y no estricto\n",
    "\n",
    "La definición del equilibrio de Nash (21.1), requiere que el resultado de desviarse no sea mejor que el resultado del equilibrio. Por tanto, el equilibrio de algunos juegos es tal que los jugadores son indiferentes entre la acción vinculada con el equilibrio y alguna otra acción, dadas las acciones de los otros jugadores. \n",
    "\n",
    "#### Juego con equilibrio (único y no estricto) de Nash \n",
    "\n",
    "|   | L  | M  | R  |\n",
    "|---|:---:|:---:|:---:|\n",
    "|  T | 1,1  | 1,0  | 0,1  |\n",
    "|  B | 1,0  | 0,1  |  1,0 |\n",
    "\n",
    "El juego tiene un equilibrio de Nash único y no estricto (T,L)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396c4bb2-3afa-44ea-8789-420b600d6d5b",
   "metadata": {},
   "source": [
    "## Funciones de mejor respuesta\n",
    "\n",
    "Sea la función $B_i$, la función de mejor respuesta del jugador $i$,\n",
    "$$\n",
    "B_i(a_{-i}) = \\{ a_i \\text{ in } A_i:u_i(a_i, a_{-i}) \\geq u_i(a_i^\\prime, a_{-i}) \\text{ para todo } a_i^\\prime \\text{ in } A_i \\}\n",
    "$$\n",
    "\n",
    "cualquier acción $B_i(a_{-i})$ es al menos tan buena para el jugador $i$ como cualquier otra acción del jugador $i$ cuando las acciones de los otros jugadores son $a_{-i}$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4987ed8-9c28-4b70-b380-e601a951d108",
   "metadata": {},
   "source": [
    "#### Proposición. \n",
    "El perfil de acciones $a^*$ es un equilibrio de Nash de un juego de estrategias con preferencias ordinales si, y solo si, las acciones de cada jugador son la mejor respuesta frente a las acciones de los otros jugadores: \n",
    "$$\n",
    "a_i^* \\text{ esta en } B_i(a_{-i}^*) \\text{ para cada jugador } i. \\tag{34.2}\n",
    "$$\n",
    "\n",
    "\n",
    "Si cada jugador $i$ tiene una sola mejore respuesta para cada lista de acciones $a_{-i}$ de las acciones de los otros jugadores, entonces podemos escribir las condiciones en (34.2) como ecuaciones. Esto es $B_i(a_{-i})=\\{b_i(a_{-i})\\}$. Entonces, (34.2) es equivalente a \n",
    "\n",
    "$$\n",
    "a_i^* = b_i(a_{-i}^*) \\text{ para cada jugador } i, \\tag{34.3}\n",
    "$$\n",
    "un grupo de $n$ ecuaciones y $n$ incognitas $a_i^*$, en donde $n$ es el número de jugadores participantes. \n",
    "\n",
    "Por ejemplo, con dos jugadores \n",
    "$$\n",
    "a_1^* = b_1(a_2^*) \\\\\n",
    "a_2^* = b_2(a_1^*)\n",
    "$$\n",
    "\n",
    "Esto es, en un juego con dos participantes en el cual cada jugador tiene una sola mejor respuesta para cada acción del otro jugador, $(a_1^*, a_2^*)$ es un equilibrio de Nash si, y solo si, la acción $a_1^*$ es la mejor respuesta ante las acciones del jugador 2 $a_2^*$, y la acción del jugador 2 $a_2^*$ es la mejor respuesta ante la acción $a_1^*$ del jugador 1. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f132da-bf61-4fee-9b66-2aec708747e8",
   "metadata": {},
   "source": [
    "#### Ejemplo de equilibrio de Nash usando las funciones de mejor respuesta\n",
    "\n",
    "|   | L  | C  | R  |\n",
    "|---|:---:|:---:|:---:|\n",
    "|  T | 1,2*  | 2*,1  | 1*,0  |\n",
    "|  M | 2*, 1*  | 0,1*  | 0,0  |\n",
    "|  B | 0,1  | 0,0  | 1*, 2*  |\n",
    "\n",
    "Se concluye que este juego tiene dos equilibrios de Nash: (M,L) y (B,R). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998c807d-9cbb-4092-b3b5-f28c5f14acc4",
   "metadata": {},
   "source": [
    "## Estragias dominantes\n",
    "\n",
    "Una acción es *estrictamente dominante\" a cualquier otra acción si es superior, sin importar que hagan los otros jugadores. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee315f28-6513-48b9-9b5a-cf2391ce5a3b",
   "metadata": {},
   "source": [
    "#### Definición (dominantes strictas)\n",
    "\n",
    "En un juego de estrategia con preferencias ordinales, la acción $a_i^{\\prime\\prime}$ estrictamente domina la acción $a_i^{\\prime}$ si \n",
    "\n",
    "$$\n",
    "u_i(a_i^{\\prime\\prime}, a_{-i}) > u_i(a_i^{\\prime}, a_{-i}) \\text{ para cada perfil de acciones } a_{-i} \n",
    "$$\n",
    "donde $u_i$ es la función de pagos que representa las preferencias del jugador $i$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41744d4-11ce-450a-9324-3f3a2bd9ef1c",
   "metadata": {},
   "source": [
    "En el dilema del prisionero, la acción *soplón* domina estrictamente a la acción *callarse*. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a0af0e-8427-4617-ae06-64fb7617b6e4",
   "metadata": {},
   "source": [
    "---\n",
    "Nota: \n",
    "Una acción que es estrictamente dominada no forma parte de ningún equilibrio de Nash. \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859a1c71-80e6-411b-819a-fa56d049cc66",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Código QR de jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8e8c56e-adf9-4d54-b7a3-92b57437c98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import qrcode\n",
    "qr = qrcode.QRCode(\n",
    "    version=1,\n",
    "    error_correction=qrcode.constants.ERROR_CORRECT_L,\n",
    "    box_size=10,\n",
    "    border=4,\n",
    ")\n",
    "qr.add_data(\"https://github.com/PedroJMA/notas-clase/blob/main/teoria-juegos/teoria-juegos-1intro.ipynb\")\n",
    "qr.make(fit=True)\n",
    "img = qr.make_image(fill_color=\"white\", back_color=\"black\")\n",
    "img.save(\"teoria-juegos-1intro.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5119608e-9764-491a-bb8b-ecca2549ac5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"teoria-juegos-1intro.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
